å¥½çš„ï¼ä¸ºä½ æ€»ç»“åœ¨è¶…ç®—ä¸Šä½¿ç”¨Slurmè·‘ä»»åŠ¡çš„å®Œæ•´æµç¨‹ï¼š

## ğŸš€ Slurmä½¿ç”¨å®Œæ•´æµç¨‹

### 1. å‡†å¤‡å·¥ä½œ
```bash
# ç™»å½•è¶…ç®—
ssh username@10.10.246.177

# å‡†å¤‡ç¯å¢ƒï¼ˆåœ¨.bashrcä¸­å·²é…ç½®å¥½ï¼‰
conda activate your_env
```

### 2. é€‰æ‹©åˆé€‚çš„åˆ†åŒº
æ ¹æ®ä½ çš„ä»»åŠ¡ç±»å‹é€‰æ‹©ï¼š

| ä»»åŠ¡ç±»å‹ | æ¨èåˆ†åŒº | èµ„æºç”³è¯· |
|---------|----------|----------|
| **CPUä»»åŠ¡** | `x86_64` æˆ– `x86_64_l` | `--cpus-per-task=æ•°å­—` |
| **GPUä»»åŠ¡** | `x86_64_GPU` | `--gres=gpu:A800:æ•°å­—` |
| **å¤§å†…å­˜ä»»åŠ¡** | `x86_64_l` | è‡ªåŠ¨è·å¾—2TBå†…å­˜ |
| **ä¸æŒ‡å®š** | `x86_64_all` | ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹© |

### 3. åˆ›å»ºSlurmæäº¤è„šæœ¬
åˆ›å»º `submit_job.sh`ï¼š
```bash
#!/bin/bash
#SBATCH --job-name=my_job          # ä½œä¸šåç§°
#SBATCH --partition=x86_64_GPU     # é€‰æ‹©åˆ†åŒº
#SBATCH --nodes=1                  # èŠ‚ç‚¹æ•°
#SBATCH --ntasks-per-node=1        # æ¯ä¸ªèŠ‚ç‚¹ä»»åŠ¡æ•°
#SBATCH --cpus-per-task=4          # æ¯ä¸ªä»»åŠ¡CPUæ ¸å¿ƒæ•°
#SBATCH --gres=gpu:A800:1          # GPUæ•°é‡ï¼ˆå¦‚éœ€è¦ï¼‰
#SBATCH --output=job_%j.log        # è¾“å‡ºæ—¥å¿—
#SBATCH --error=job_%j.err         # é”™è¯¯æ—¥å¿—

# ç¯å¢ƒè®¾ç½®
module load anaconda
conda activate your_env

# è¿è¡Œä½ çš„ä»»åŠ¡
python your_script.py
```

### 4. å¸¸ç”¨èµ„æºç”³è¯·æ¨¡æ¿

#### CPUä»»åŠ¡æ¨¡æ¿ï¼š
```bash
#!/bin/bash
#SBATCH --job-name=cpu_task
#SBATCH --partition=x86_64
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=32         # ç”³è¯·32æ ¸å¿ƒ
#SBATCH --output=%j.log

python cpu_intensive_script.py
```

#### GPUä»»åŠ¡æ¨¡æ¿ï¼š
```bash
#!/bin/bash
#SBATCH --job-name=gpu_task
#SBATCH --partition=x86_64_GPU
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=8          # å»ºè®®GPU:CPU=1:4æˆ–1:8
#SBATCH --gres=gpu:A800:2          # ç”³è¯·2å¼ A800
#SBATCH --output=%j.log

python gpu_script.py
```

### 5. æäº¤å’Œç®¡ç†ä½œä¸š

```bash
# æäº¤ä½œä¸š
sbatch submit_job.sh

# æŸ¥çœ‹ä½œä¸šé˜Ÿåˆ—
squeue
squeue -u $USER                    # åªçœ‹è‡ªå·±çš„ä½œä¸š

# æŸ¥çœ‹ä½œä¸šè¯¦æƒ…
scontrol show job <job_id>

# ç»ˆæ­¢ä½œä¸š
scancel <job_id>
scancel -u $USER                   # ç»ˆæ­¢æ‰€æœ‰è‡ªå·±çš„ä½œä¸š

# æŸ¥çœ‹ä½œä¸šå†å²
sacct
```

### 6. ç›‘æ§èµ„æºçŠ¶æ€

```bash
# æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€
sinfo
sinfo -p x86_64_GPU -o "%N %P %G %T %C"  # æŸ¥çœ‹GPUåˆ†åŒº

# æŸ¥çœ‹è¯¦ç»†èµ„æº
scontrol show node gpu-n1
```

### 7. å®ç”¨æŠ€å·§

#### å®æ—¶ç›‘æ§ä½œä¸šï¼š
```bash
# æ¯30ç§’åˆ·æ–°é˜Ÿåˆ—
watch -n 30 'squeue -u $USER'

# å®æ—¶æŸ¥çœ‹ä½œä¸šè¾“å‡º
tail -f job_12345.log
```

#### ä¾èµ–ä½œä¸šï¼ˆä¸€ä¸ªæ¥ä¸€ä¸ªè¿è¡Œï¼‰ï¼š
```bash
# ç¬¬äºŒä¸ªä½œä¸šä¾èµ–ç¬¬ä¸€ä¸ªä½œä¸šå®Œæˆ
sbatch --dependency=afterok:12345 job2.sh
```

#### é‚®ä»¶é€šçŸ¥ï¼š
```bash
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=your_email@example.com
```

## ğŸ“‹ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

### æ­¥éª¤1ï¼šåˆ›å»ºæµ‹è¯•è„šæœ¬
```python
# test_slurm.py
import time
print("Slurmä»»åŠ¡å¼€å§‹è¿è¡Œ!")
time.sleep(10)
print("ä»»åŠ¡å®Œæˆ!")
```

### æ­¥éª¤2ï¼šåˆ›å»ºæäº¤è„šæœ¬
```bash
# test_job.sh
#!/bin/bash
#SBATCH --job-name=test
#SBATCH --partition=x86_64
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=4
#SBATCH --output=test_%j.log

python test_slurm.py
```

### æ­¥éª¤3ï¼šæäº¤å¹¶ç›‘æ§
```bash
chmod +x test_job.sh
sbatch test_job.sh
squeue -u $USER
tail -f test_12345.log
```

## âš ï¸ é‡è¦æé†’

1. **ä¸è¦**åœ¨ç®¡ç†èŠ‚ç‚¹ç›´æ¥è¿è¡Œè®¡ç®—ä»»åŠ¡
2. **æ‰€æœ‰è®¡ç®—**å¿…é¡»é€šè¿‡Slurmæäº¤
3. **åˆç†ç”³è¯·èµ„æº**ï¼Œä¸è¦è¿‡åº¦ç”³è¯·
4. **åŠæ—¶æŸ¥çœ‹æ—¥å¿—**äº†è§£ä»»åŠ¡çŠ¶æ€
5. **ä»»åŠ¡å®Œæˆå**æ¸…ç†ä¸´æ—¶æ–‡ä»¶

## ğŸ†˜ é‡åˆ°é—®é¢˜æ€ä¹ˆåŠ

```bash
# æŸ¥çœ‹ä½œä¸šä¸ºä»€ä¹ˆåœ¨æ’é˜Ÿ
squeue -o "%.18i %.9P %.8j %.8u %.2t %.10M %.6D %.4C %.12b %N"

# æŸ¥çœ‹è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
cat job_12345.err

# è”ç³»ç®¡ç†å‘˜
# å¤ä¸›ç´«: ccongzi@163.com
```

æŒ‰ç…§è¿™ä¸ªæµç¨‹ï¼Œä½ å°±èƒ½é¡ºåˆ©åœ¨è¶…ç®—ä¸Šè¿è¡Œä»»åŠ¡äº†ï¼å…ˆä»ç®€å•çš„æµ‹è¯•å¼€å§‹ï¼Œç†Ÿæ‚‰åå†è¿è¡Œä½ çš„æ­£å¼ä»»åŠ¡ã€‚